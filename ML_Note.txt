			1. Introduction to Machine Learning
Machine Learning (ML) is the art of teaching computers to recognize patterns and make decisions based on data. It replaces rigid "if-then" programming with algorithms that "figure it out" themselves.

		1.1 The Evolution of Definitions
 - The Conceptual Vision (Samuel, 1959): The field of study that gives computers the ability to learn without being explicitly programmed.
 - The Technical Framework (Mitchell, 1997): A program learns from Experience (E) with respect to a Task (T) and a Performance measure (P), if its performance at T, measured by P, improves with E.

		1.2 Practical Milestone
 - The 1990s Spam Filter: The first major real-world application. It perfectly illustrates the framework: The Task is filtering, the Experience is user-marked junk mail, and Performance is the accuracy of future blocks.

			2. Types of Machine Learning

		2.1 Supervised Learning (Learning with a "Teacher")
The model is trained on a labeled dataset (an answer key). It learns a general rule to map inputs to the correct outputs.
The Vocabulary of Supervised Learning:
 - Inputs: Often called Features, Predictors, or Attributes.
 - Outputs: * Target: Used in Regression (predicting continuous numbers, e.g., house prices).
 - Label: Used in Classification (predicting discrete categories, e.g., "Spam" vs "Not Spam").

		2.2 Unsupervised Learning (Self-Discovery)
The "teacher" (labels) is removed. The machine is given only unlabeled data and must find hidden structures or anomalies on its own.
> Key Technique: Dimensionality Reduction
When a dataset has too many redundant Predictors, we use Dimensionality Reduction to simplify it, making models faster and preventing overfitting.
 - Feature Extraction: An approach where we merge correlated features into a single, new feature.
    - Example: Merging "Years of Education" and "Starting Salary" into one "latent" variable.
    - Mechanism: It transforms data from high-dimensional space to a lower-dimensional space while keeping essential information.
	
		2.3 Hybrid and Advanced Learning Types
  - Semi-supervised Learning: A middle ground where the dataset contains a small amount of labeled data and a large amount of unlabeled data. The model uses the labeled data to get a "head start" and then explores the unlabeled data to refine its understanding.
  - Self-supervised Learning: A subset of unsupervised learning where the system generates its own labels from the data. For example, hiding a word in a sentence and asking the model to predict it (this is how Large Language Models like me are trained).
  - Transfer Learning: The act of taking a model trained on one task (e.g., recognizing cars) and "transferring" that knowledge to a new, related task (e.g., recognizing trucks). It saves time and requires much less data.
  - Reinforcement Learning (RL): An agent learns by interacting with an environment. It receives rewards for good actions and penalties for bad ones.
      - Policy: The "best strategy" or mapping from states to actions that the agent follows to maximize rewards.
      - Offline Learning: Training the agent using a fixed dataset of previous interactions rather than letting it learn through live, real-time trial and error.

		2.4 Data Flow: Batch vs. Online Learning
How does the model handle new data once it is deployed?
	- Batch Learning (Offline): The system is incapable of learning incrementally. It must be trained using all available data (new + old).
	  - Model Rot/Data Drift: Since the model is "static," its performance decays over time as the real-world data changes (e.g., a 2010 real estate model won't work in 2026).
	- Online Learning: The system learns incrementally by feeding it data instances individually or in small groups (mini-batches).
	  - Learning Rate: A parameter that determines how quickly the model should "forget" old patterns to adopt new ones.
	  - Out-of-core Learning: A huge advantage; it allows the system to train on datasets that are too large to fit into a computerâ€™s main memory (RAM).

		2.5 Generalization: Instance-Based vs. Model-Based
How does the machine actually make a prediction on a new piece of data?
	- Instance-Based Learning: The system learns the training examples by heart. To generalize to a new case, it uses a similarity measure to find the most similar learned examples (e.g., "This new email looks exactly like these 3 spam emails I saw earlier").
	- Model-Based Learning: The system builds a mathematical model (like a line or a curve) from the examples.
	 - Model Selection: Choosing the right architecture (e.g., a Linear Regression vs. a Neural Network).
	 - Model Training: The process of running an algorithm to find the parameters (weights) that allow the model to best fit the training data.






	 
	 
